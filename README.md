## üë®üèª‚Äçüî¨ Research Interests

**Reinforcement Learning**
- Core contributor of [Reasoning Gym](https://github.com/open-thought/reasoning-gym) where I built dozens of RL environments, as well as ran the zero-shot, external benchmark, and curriculum learning experiments for our NeurIPS publication.
- Wrote several sections of the [RLHF Book](https://rlhfbook.com), where I derived the [policy gradient objective](https://github.com/natolambert/rlhf-book/pull/136) and [Bradley-Terry loss](https://github.com/natolambert/rlhf-book/pull/97), provided intuitions for the [PPO gradient dynamics](https://github.com/natolambert/rlhf-book/pull/139), and built the foundations of the [code library](https://github.com/natolambert/rlhf-book/pull/219).

**Healthcare and Life Sciences**
- Led a team to automate glomerular sclerosis classification from gigapixel kidney biopsies, deployed in a system serving over half of the [Organ Procurement Organizations](https://www.einpresswire.com/article/843275598/loka-supports-specialist-direct-in-expanding-its-market-leading-transplantai-platform) in the US.
- Part of a team developing models to predict protein-ligand binding affinity from DNA Encoded Library (DEL) data for [drug discovery](https://ir.nurixtx.com/news-releases/news-release-details/nurix-therapeutics-presents-data-aacr-2025-annual-meeting), resulting in numerous experimentally confirmed binders in the lab!

**Continual Learning**
- Worked on mitigating catastrophic forgetting in foundation models based on continual weight interpolation, [demonstrating](https://arxiv.org/abs/2211.03186) performance close to the upper bound of jointly training on all data in our NeurIPS workshop publication.
  
**Evaluation**
- Contributed several datasets to EleutherAI‚Äôs Evaluation Harness (e.g. [Lambada Translations](https://github.com/EleutherAI/lm-evaluation-harness/pull/1897), [Paloma](https://github.com/EleutherAI/lm-evaluation-harness/pull/1928), [LegalBench](https://github.com/EleutherAI/lm-evaluation-harness/pull/1878)), as well as implemented [higher-is-better indicators](https://github.com/EleutherAI/lm-evaluation-harness/pull/1893) and tests for [output table consistency](https://github.com/EleutherAI/lm-evaluation-harness/pull/1916).
- Built [Word Game Bench](https://wordgamebench.github.io) ‚Äì an evaluation suite based on Wordle and Connections ‚Äì which I ran on the new daily puzzles for several months in 2024 (sponsored by OpenRouter).

## üìÑ Publications

My work is used by AI labs such as DeepMind [[1](https://arxiv.org/abs/2401.12187), [2](https://arxiv.org/abs/2406.16768), [3](https://arxiv.org/abs/2411.15099), [4](https://arxiv.org/abs/2408.14471)], Meta [[5](https://arxiv.org/abs/2212.10445), [6](https://arxiv.org/abs/2306.04488), [7](https://arxiv.org/abs/2508.13141)], NVIDIA [[8](https://arxiv.org/abs/2507.12507), [9](https://arxiv.org/abs/2510.01180)], Mila [[10](https://arxiv.org/abs/2509.26626), [11](https://arxiv.org/abs/2505.24273), [12](https://arxiv.org/abs/2505.14970)], and Prime Intellect [[13](https://www.primeintellect.ai/blog/synthetic-2])]:
- **"[Reasoning Gym: Reasoning Environments for RL with Verifiable Rewards](https://arxiv.org/abs/2505.24760)."** **<ins>Zafir Stojanovski</ins>**\*, Oliver Stanley\*, Joe Sharratt\*, Richard Jones\*, Abdulhakeem Adefioye, Jean Kaddour, Andreas K√∂pf. **<ins>NeurIPS 2025</ins>** (Spotlight)
- **"[Momentum-based Weight Interpolation of Strong Zero-Shot Models for Continual Learning](https://arxiv.org/abs/2211.03186)."** **<ins>Zafir Stojanovski</ins>**\*, Karsten Roth\*, Zeynep Akata. Interpolate Workshop @ **<ins>NeurIPS 2022</ins>** (Best Paper Award)
